{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2_model import *\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.func import jacrev\n",
    "from copy import deepcopy\n",
    "\n",
    "external_path=''\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_lre(folder,filename,sample_size,block,model,tokenizer,external_path,target_obj_toks):\n",
    "    prompts_file=open(f'relation_data/text/{folder}/{filename}.txt','r')\n",
    "    prompts_no_object_file=open(f'../relation_data/text_no_object/{folder}/{filename}.txt','r')\n",
    "    indices_file=open(f'relation_data/index/{folder}/{filename}.txt','r')\n",
    "    prompts=[prompt.split('\\n')[0] for prompt in prompts_file.readlines()]\n",
    "    prompts_no_object=[prompt.split('\\n')[0] for prompt in prompts_no_object_file.readlines()]\n",
    "    indices=[[int(line.split(',')[0]),int(line.split(',')[1]),int(line.split(',')[2])] for line in indices_file.readlines()]\n",
    "    prompts_file.close()\n",
    "    prompts_no_object_file.close()\n",
    "    indices_file.close()\n",
    "\n",
    "    for n in range(5):\n",
    "        sample_positions=np.sort(np.random.randint(low=0,high=len(prompts),size=sample_size,dtype=int))\n",
    "        s_c_o=[]\n",
    "\n",
    "        for rel_pos,abs_pos in enumerate(sample_positions):\n",
    "            prefix_indices=np.delete(sample_positions,rel_pos)\n",
    "            prefix_text=' '.join([prompts[i]+'.' for i in prefix_indices])\n",
    "            end_sub_token_pos=len(tokenizer(prefix_text).input_ids)+indices[abs_pos][0]\n",
    "            text=prefix_text+' '+prompts_no_object[abs_pos]\n",
    "            beg_obj_token_pos=len(tokenizer(text).input_ids)\n",
    "            s_c_o.append([end_sub_token_pos,text,[beg_obj_token_pos,indices[abs_pos][-1]]])\n",
    "        \n",
    "        jac_size=len(target_obj_toks)\n",
    "        jacobian=torch.zeros((jac_size,768))\n",
    "        bias=torch.zeros(jac_size)\n",
    "        count=np.zeros(sample_size)\n",
    "        for k,triple in enumerate(s_c_o):\n",
    "            sub_act=model.forward_with_activation_return(tokenizer(triple[1],return_tensors='pt').input_ids,block,triple[0])[1]\n",
    "            obj_idx_logits=model.forward(tokenizer(triple[1],return_tensors='pt').input_ids)[0][0,-1,:]\n",
    "            if obj_idx_logits.argmax()==triple[-1][-1]:\n",
    "                func = lambda x:model.F(tokenizer(triple[1],return_tensors='pt').input_ids,block,triple[0],x,-1)[target_obj_toks]  \n",
    "\n",
    "                ft_jacobian=jacrev(func)(sub_act)\n",
    "                jacobian+=ft_jacobian.squeeze(1)\n",
    "                bias+=obj_idx_logits[target_obj_toks]-jacobian@sub_act.squeeze(0)\n",
    "                count[k]=1\n",
    "        sum_count=np.sum(count)\n",
    "        if sum_count!=0:\n",
    "            jacobian=jacobian/sum_count\n",
    "            bias=bias/sum_count\n",
    "            torch.save(jacobian,f'{external_path}\\\\{folder}\\\\{filename}_jacobian.pt')\n",
    "            torch.save(bias,f'{external_path}\\\\{folder}\\\\{filename}_bias.pt')\n",
    "            return s_c_o, count\n",
    "    return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faithfulness(folder,filename,external_path,model,tokenizer,num_supporting_prompts,target_obj_toks,block,top_k=1,beta=1):\n",
    "\n",
    "    index_file=open(f'relation_data/index/{folder}/{filename}.txt','r')\n",
    "    index_file_lines=index_file.readlines()\n",
    "    end_sub_idxs=[int(line.split(',')[0]) for line in index_file_lines]\n",
    "    beg_obj_toks=[int(line.split(',')[-1]) for line in index_file_lines]\n",
    "    index_file.close()\n",
    "\n",
    "    prompts_file=open(f'relation_data/text_no_object/{folder}/{filename}.txt','r')\n",
    "    prompts=[line.split('\\n')[0] for line in prompts_file]\n",
    "    prompts_file.close()\n",
    "\n",
    "    prompts_with_object_file=open(f'relation_data/text/{folder}/{filename}.txt','r')\n",
    "    prompts_with_object=[line.split('\\n')[0] for line in prompts_with_object_file]\n",
    "    prompts_with_object_file.close()\n",
    "    N=len(prompts_with_object)\n",
    "\n",
    "    jacobian=torch.load(f'{external_path}\\\\{folder}\\\\{filename}_jacobian.pt')\n",
    "    bias=torch.load(f'{external_path}\\\\{folder}\\\\{filename}_bias.pt')\n",
    "\n",
    "    count=0\n",
    "    accuracy=0\n",
    "    for n,prompt_token in enumerate(prompts):\n",
    "        support_prompts_idx=np.random.choice(np.delete(np.arange(N),n),num_supporting_prompts)\n",
    "\n",
    "        prefix_text=' '.join([prompts_with_object[i]+'.' for i in support_prompts_idx])\n",
    "        end_sub_token_pos=len(tokenizer(prefix_text).input_ids)+end_sub_idxs[n]\n",
    "\n",
    "        text=prefix_text+' '+prompts[n]\n",
    "        prompt_token=tokenizer(text,return_tensors='pt').input_ids\n",
    "        beg_obj_tok_idx=len(prompt_token)\n",
    "\n",
    "        beg_obj_idx_logits=model.forward(prompt_token)[0][0,-1,:]\n",
    "        if beg_obj_idx_logits.argmax()==beg_obj_toks[n]:\n",
    "            count+=1\n",
    "            sub_act=model.forward_with_activation_return(prompt_token,block,end_sub_token_pos)[1]\n",
    "            lre=beta*jacobian@sub_act.squeeze(0)+bias\n",
    "            beg_obj_idx_logits_with_lre=deepcopy(beg_obj_idx_logits.detach())\n",
    "            beg_obj_idx_logits_with_lre[target_obj_toks]=lre.detach()\n",
    "            if beg_obj_toks[n] in torch.argsort(beg_obj_idx_logits_with_lre,descending=True)[:top_k]:\n",
    "                accuracy+=1\n",
    "    if count!=0:\n",
    "        return accuracy/count\n",
    "    return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2=GPT(GPTConfig).from_pretrained('gpt2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size=8\n",
    "num_supporting_prompts=7\n",
    "\n",
    "experiment_no=9\n",
    "beta=16\n",
    "top_k=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories={}\n",
    "for folder in os.listdir('relation_data/text'):\n",
    "    files=[]\n",
    "    for filename in os.listdir(f'relation_data/text/{folder}'):\n",
    "        file=open(f'relation_data/text/{folder}/{filename}','r')\n",
    "        if len(file.readlines())<250:\n",
    "            files.append(filename.split('.')[0])\n",
    "        file.close()\n",
    "    directories[folder]=files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(os.path.exists(f'../faithfulness/experiment_{experiment_no}')):\n",
    "    os.mkdir(f'../faithfulness/experiment_{experiment_no}')\n",
    "    experiment_file=open(f'../faithfulness/experiment_{experiment_no}/experiment_details.txt','w')\n",
    "    experiment_file.write(f'num_supporting_prompts={num_supporting_prompts}\\nbeta={beta}\\ntop_k={top_k}')\n",
    "    experiment_file.close()\n",
    "\n",
    "for block_number in range(1,10+1):\n",
    "\n",
    "    faithfulness_dict={}\n",
    "    updated_external_path=f'{external_path}\\\\gpt2\\\\lres\\\\{block_number}'\n",
    "\n",
    "    if not(os.path.exists(f'{updated_external_path}')):\n",
    "        os.mkdir(f'{updated_external_path}')\n",
    "        for folder in directories.keys():\n",
    "            os.mkdir(f'{updated_external_path}\\\\{folder}')\n",
    "        get_jacobian=True\n",
    "    else:\n",
    "        get_jacobian=False\n",
    "    K=len(directories)\n",
    "    for k,folder in enumerate(directories):\n",
    "\n",
    "        if get_jacobian:\n",
    "            file=open(f'{updated_external_path}\\\\{folder}\\\\estimating_jacobian.txt','w')\n",
    "            file.write(f'Block:{block_number}\\nSamples:{sample_size}\\n')\n",
    "        else:\n",
    "            file=open(f'{updated_external_path}\\\\{folder}\\\\estimating_jacobian.txt','r')\n",
    "            file_lines=file.readlines()\n",
    "\n",
    "        progress_bar=tqdm.tqdm(enumerate(directories[folder]))\n",
    "        N=len(directories[folder])\n",
    "        for n,filename in progress_bar:\n",
    "            progress_bar.set_description(f'Block {block_number}...processing {folder}/{filename} ({n+1}/{N})/({k+1}/{K})...')\n",
    "\n",
    "            indices=open(f'../relation_data/index/{folder}/{filename}.txt','r')\n",
    "            target_obj_toks=list(set([int(line.split(',')[-1]) for line in indices.readlines()]))\n",
    "            target_obj_toks.sort()\n",
    "            indices.close()\n",
    "\n",
    "            if get_jacobian:\n",
    "                outcome=estimate_lre(folder,filename,sample_size,block_number,gpt2,tokenizer,updated_external_path,target_obj_toks)\n",
    "                if outcome=='None':\n",
    "                    file.write(f'{filename}: None\\n')\n",
    "                    faithfulness_dict[f'{folder}/{filename}']='None'\n",
    "                else:\n",
    "                    file.write(f'{filename}: {outcome[0]} {outcome[1]}\\n')\n",
    "                    accuracy=faithfulness(folder,filename,updated_external_path,gpt2,tokenizer,num_supporting_prompts,target_obj_toks,block_number)\n",
    "                    faithfulness_dict[f'{folder}/{filename}']=accuracy\n",
    "            else:\n",
    "                outcome=file_lines[n+2] \n",
    "                if outcome=='None':\n",
    "                    faithfulness_dict[f'{folder}/{filename}']='None'\n",
    "                else:\n",
    "                    accuracy=faithfulness(folder,filename,updated_external_path,gpt2,tokenizer,num_supporting_prompts,target_obj_toks,block_number,top_k,beta)\n",
    "                    faithfulness_dict[f'{folder}/{filename}']=accuracy \n",
    "        file.close()\n",
    "\n",
    "    faithfulness_file=open(f'../faithfulness/experiment_{experiment_no}/faithfulness_{block_number}','wb')\n",
    "    pickle.dump(faithfulness_dict,faithfulness_file)\n",
    "    faithfulness_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_dict={}\n",
    "max_accuracies_dict={}\n",
    "for n,file in enumerate(os.listdir(f'faithfulness/experiment_{experiment_no}')):\n",
    "    if 'png' in file or 'txt' in file:\n",
    "        continue\n",
    "    faithfulness_file=open(f'faithfulness/experiment_{experiment_no}/{file}','rb')\n",
    "    accuracies=pickle.load(faithfulness_file)\n",
    "    faithfulness_file.close()\n",
    "\n",
    "    for relation,acc in accuracies.items():\n",
    "        if relation in accuracies_dict.keys():\n",
    "            if acc=='None':\n",
    "                accuracies_dict[relation]=(accuracies_dict[relation][0]+[0],accuracies_dict[relation][1])\n",
    "            elif acc>max(accuracies_dict[relation][0]):\n",
    "                accuracies_dict[relation]=(accuracies_dict[relation][0]+[acc],int(file.split('_')[-1].split('.')[0]))\n",
    "                max_accuracies_dict[relation]=(acc,int(file.split('_')[-1].split('.')[0]))\n",
    "            else:\n",
    "                accuracies_dict[relation]=(accuracies_dict[relation][0]+[acc],accuracies_dict[relation][1])\n",
    "        else:\n",
    "            if acc=='None':\n",
    "                accuracies_dict[relation]=([0],int(file.split('_')[-1].split('.')[0]))\n",
    "                max_accuracies_dict[relation]=(0,int(file.split('_')[-1].split('.')[0]))\n",
    "            else:\n",
    "                accuracies_dict[relation]=([acc],int(file.split('_')[-1].split('.')[0]))\n",
    "                max_accuracies_dict[relation]=(acc,int(file.split('_')[-1].split('.')[0]))\n",
    "\n",
    "max_accuracies_file=open(f'faithfulness/experiment_{experiment_no}/faithfulness_combined','wb')\n",
    "pickle.dump(max_accuracies_dict,max_accuracies_file)\n",
    "max_accuracies_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_file=open(f'faithfulness/experiment_{experiment_no}/experiment_details.txt','r')\n",
    "experiment_parameters=[int(line.split('=')[-1]) for line in experiment_file.readlines()]\n",
    "experiment_file.close()\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "neg_heights=np.array([-max(heights) for heights,block in accuracies_dict.values()])\n",
    "relation_labels=np.array([label for label in accuracies_dict.keys()])\n",
    "sorted_indices=np.argsort(neg_heights)\n",
    "\n",
    "x=0\n",
    "xlocs=[]\n",
    "xlabs=[]\n",
    "for relation in relation_labels[sorted_indices]:\n",
    "    max_block=accuracies_dict[relation][1]\n",
    "    heights=accuracies_dict[relation][0]\n",
    "    heights=[-height for height in heights]\n",
    "    heights.sort()\n",
    "    heights=[-height for height in heights]\n",
    "    for height in heights:\n",
    "        ax.bar(x,height,color='white',edgecolor='black')\n",
    "\n",
    "    xlocs.append(x)\n",
    "    xlabs.append(relation+' ('+str(max_block)+')')\n",
    "\n",
    "    x+=1\n",
    "ax.set_ylim((0,1.05))\n",
    "ax.set_xticks(xlocs,xlabs,rotation='vertical')\n",
    "ax.set_title(f'Beta={experiment_parameters[1]}, Top {experiment_parameters[2]}')\n",
    "plt.savefig(f'faithfulness/experiment_{experiment_no}/faithfulness_plot.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
