{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=125\n",
    "LEARNING_RATE=0.01\n",
    "EPOCHS=4\n",
    "\n",
    "number_trained_cnns=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_TRAIN = torchvision.datasets.MNIST(root='data',train=True, transform=transforms.ToTensor(), download=True)\n",
    "DATASET_TEST = torchvision.datasets.MNIST(root='data',train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "LOADER_TRAIN = DataLoader(dataset=DATASET_TRAIN, batch_size=BATCH_SIZE, shuffle=True)\n",
    "LOADER_TEST = DataLoader(dataset=DATASET_TEST, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1,64,3,1,padding='same'),nn.ReLU(),nn.MaxPool2d(2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(64,32,3,1,padding='same'),nn.ReLU(),nn.MaxPool2d(2))\n",
    "        self.fc = nn.Sequential(nn.Linear(1568,32),nn.ReLU())\n",
    "        self.out = nn.Sequential(nn.Linear(32, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar=tqdm(range(number_trained_cnns))\n",
    "for n in progress_bar:\n",
    "    model = ConvNet()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        if epoch in [1,4,9]:\n",
    "            np.save(f'trained_cnns/model_{n+1}_epoch{epoch}_batch125_weights',model.conv1[0].weight.data.numpy())\n",
    "        for i, (images, labels) in enumerate(LOADER_TRAIN):\n",
    "            b_x = Variable(images) \n",
    "            b_y = Variable(labels)\n",
    "            output=model(b_x)\n",
    "            loss=criterion(output, b_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        progress_bar.set_description(f'CNN [{n+1}/{number_trained_cnns}], Epoch [{epoch+1}/{EPOCHS}]')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in LOADER_TEST:\n",
    "            test_output = model(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "    f = open(\"test_data_cnns.txt\", \"a\")\n",
    "    f.write(\"CNN {}: Test Accuracy {}\\n\".format(n+1,accuracy))\n",
    "    f.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
