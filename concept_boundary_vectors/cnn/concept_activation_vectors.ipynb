{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from src import *\n",
    "\n",
    "external_path=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_dimension: int, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_dimension=in_dimension\n",
    "        self.linear=torch.nn.Linear(in_dimension,1)\n",
    "        self.sigmoid=torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(positive_digit,negative_digit):\n",
    "    positive_digit_activations=torch.load(f'{external_path}\\\\latent_activations\\\\{positive_digit}.pt')\n",
    "    negative_digit_activations=torch.load(f'{external_path}\\\\latent_activations\\\\{negative_digit}.pt')\n",
    "\n",
    "    latent_space_activations=torch.cat([positive_digit_activations,negative_digit_activations])\n",
    "\n",
    "    dataset_size=positive_digit_activations.shape[0]+negative_digit_activations.shape[0]\n",
    "\n",
    "    labels=torch.cat([torch.ones(positive_digit_activations.shape[0]),torch.zeros(negative_digit_activations.shape[0])])\n",
    "    perm=torch.randperm(dataset_size)\n",
    "\n",
    "    dataset=(latent_space_activations[perm].detach(),labels[perm].detach())\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset,batch_size=64,lr=1e-3,epochs=100,verbose=False):\n",
    "\n",
    "    latent_space_dim=dataset[0].shape[1]\n",
    "    dataset_size=dataset[0].shape[0]\n",
    "\n",
    "    model=LinearClassifier(latent_space_dim)\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion=torch.nn.BCELoss()\n",
    "\n",
    "    if verbose:\n",
    "        progress_bar=tqdm(range(epochs))\n",
    "    else:\n",
    "        progress_bar=range(epochs)\n",
    "\n",
    "    for epoch in progress_bar:\n",
    "        epoch_loss=0\n",
    "        epoch_cycles=dataset_size//batch_size\n",
    "        for k in range(epoch_cycles+1):\n",
    "            optimizer.zero_grad()\n",
    "            if k==epoch_cycles:\n",
    "                inputs=dataset[0][-k*batch_size:]\n",
    "                labels=dataset[1][-k*batch_size:]\n",
    "            else:\n",
    "                inputs=dataset[0][k*batch_size:(k+1)*batch_size]\n",
    "                labels=dataset[1][k*batch_size:(k+1)*batch_size]\n",
    "            outputs=model(inputs).reshape((len(labels),))\n",
    "            loss=criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss+=loss\n",
    "        if verbose:\n",
    "            progress_bar.set_description(f\"Loss={epoch_loss/dataset_size:.4f}\")\n",
    "        if loss<1e-5 and epoch>=49:\n",
    "            break\n",
    "    return model, epoch_loss/dataset_size, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concept_vector(model):\n",
    "    cav=model.linear.weight[0].detach()\n",
    "    return cav/torch.norm(cav,p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...processing digit 9 (8/10)...: 100%|██████████| 10/10 [03:21<00:00, 20.18s/it]\n"
     ]
    }
   ],
   "source": [
    "losses_file=open(f'{external_path}\\\\concept_activation_vectors\\\\losses.txt','w')\n",
    "\n",
    "progress_bar=tqdm(range(10))\n",
    "\n",
    "for positive_digit in progress_bar:\n",
    "    for negative_digit in range(10):\n",
    "        if positive_digit==negative_digit:\n",
    "            continue\n",
    "        progress_bar.set_description(f'...processing digit {positive_digit} ({negative_digit}/10)...')\n",
    "        dataset=get_dataset(positive_digit,negative_digit)\n",
    "        model,loss,epoch=train(dataset)\n",
    "        cav=concept_vector(model)\n",
    "        torch.save(cav,f'{external_path}\\\\concept_activation_vectors\\\\{positive_digit}_{negative_digit}.pt')\n",
    "\n",
    "        losses_file.write(f'{positive_digit}-{negative_digit},{loss}\\n')\n",
    "\n",
    "losses_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
