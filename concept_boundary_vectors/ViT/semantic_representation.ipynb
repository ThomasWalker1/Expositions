{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import einops\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "external_path=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"uoft-cs/cifar10\")\n",
    "\n",
    "train_set = dataset[\"train\"]\n",
    "test_set = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(torch.nn.Module):\n",
    "    def __init__(self, activation_size, n_dict_components, t_type=torch.float32):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.decoder = torch.nn.Linear(n_dict_components, activation_size, bias=True)\n",
    "        self.encoder_bias= torch.nn.Parameter(torch.zeros(n_dict_components))\n",
    "        torch.nn.init.orthogonal_(self.decoder.weight)\n",
    "        self.decoder = self.decoder.to(t_type)\n",
    "        self.encoder = torch.nn.Sequential(torch.nn.ReLU()).to(t_type)\n",
    "        self.activation_size = activation_size\n",
    "        self.n_dict_components = n_dict_components\n",
    "\n",
    "    def forward(self, x):\n",
    "        c=self.encoder(x@self.decoder.weight+self.encoder_bias)\n",
    "        self.decoder.weight.data=torch.nn.functional.normalize(self.decoder.weight.data,dim=0)\n",
    "        x_hat=self.decoder(c)\n",
    "        return x_hat,c\n",
    "    \n",
    "def AutoEncoderLoss(inputs,target,alpha=1e-3):\n",
    "    return torch.norm(target-inputs[0],p=2,dim=1).pow(2)+alpha*torch.norm(inputs[1],p=1,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_dictionary_construction(concepts,layer,expansion_factor=4,epochs=50,batch_size=128,lr=1e-3,alpha=1e-3):\n",
    "    for n,category in enumerate(concepts):\n",
    "        for k in range(1,11):\n",
    "            if n==0 and k==1:\n",
    "                activations=torch.load(f'{external_path}\\\\concept_token_activations\\\\{category}\\\\layer{layer}_{k}.pt').squeeze(1)\n",
    "            else:\n",
    "                activations=torch.cat([activations,torch.load(f'{external_path}\\\\concept_token_activations\\\\{category}\\\\layer{layer}_{k}.pt').squeeze(1)])\n",
    "    activations=activations.detach()\n",
    "\n",
    "    sparse_autoencoder=AutoEncoder(activations.shape[1],expansion_factor*activations.shape[1])\n",
    "    optimizer=torch.optim.Adam(sparse_autoencoder.parameters(),lr=lr)\n",
    "\n",
    "    dataset_size=activations.shape[0]\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss=0\n",
    "        epoch_cycles=dataset_size//batch_size\n",
    "        if dataset_size%batch_size==0:\n",
    "            epoch_cycles+=1\n",
    "        \n",
    "        for k in range(epoch_cycles):\n",
    "            if k==epoch_cycles-1:\n",
    "                epoch_activations=activations[k*batch_size:,:]\n",
    "            else:\n",
    "                epoch_activations=activations[k*batch_size:(k+1)*batch_size,:]\n",
    "            optimizer.zero_grad()\n",
    "            outputs=sparse_autoencoder(epoch_activations)\n",
    "            loss=AutoEncoderLoss(outputs,epoch_activations,alpha).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss+=loss*epoch_activations.shape[0]\n",
    "        epoch_loss/=activations.shape[0]\n",
    "    return sparse_autoencoder,epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "truck_ship: 100%|██████████| 10/10 [46:01<00:00, 276.16s/it]                           \n"
     ]
    }
   ],
   "source": [
    "layer=1\n",
    "if not(os.path.exists(f'{external_path}\\\\features\\\\{layer}')):\n",
    "    os.makedirs(f'{external_path}\\\\features\\\\{layer}')\n",
    "pbar=tqdm(concepts)\n",
    "for positive_concept in pbar:\n",
    "    for negative_concept in concepts:\n",
    "        if positive_concept==negative_concept:\n",
    "            continue\n",
    "        pbar.set_description(f'{positive_concept}_{negative_concept}')\n",
    "        if os.path.exists(f'{external_path}\\\\features\\\\{layer}\\\\losses'):\n",
    "            losses_file=open(f'{external_path}\\\\features\\\\{layer}\\\\losses','rb')\n",
    "            losses=pickle.load(losses_file)\n",
    "            losses_file.close()\n",
    "        else:\n",
    "            losses={}\n",
    "\n",
    "        if not(os.path.exists(f'{external_path}\\\\features\\\\{layer}\\\\{positive_concept}_{negative_concept}')):\n",
    "            os.mkdir(f'{external_path}\\\\features\\\\{layer}\\\\{positive_concept}_{negative_concept}')\n",
    "\n",
    "        if os.path.exists(f'{external_path}\\\\features\\\\{layer}\\\\{negative_concept}_{positive_concept}'):\n",
    "            model_state_dict=torch.load(f'{external_path}\\\\features\\\\{layer}\\\\{negative_concept}_{positive_concept}\\\\model.pt')\n",
    "            torch.save(model_state_dict,f'{external_path}\\\\features\\\\{layer}\\\\{positive_concept}_{negative_concept}\\\\model.pt')\n",
    "            losses[f'{positive_concept}_{negative_concept}']=losses[f'{negative_concept}_{positive_concept}']\n",
    "        else:\n",
    "            pbar.set_description(f'{positive_concept}_{negative_concept}...training model...')\n",
    "            model,loss=feature_dictionary_construction([positive_concept,negative_concept],layer)\n",
    "            torch.save(model.state_dict(),f'{external_path}\\\\features\\\\{layer}\\\\{positive_concept}_{negative_concept}\\\\model.pt')\n",
    "            losses[f'{positive_concept}_{negative_concept}']=loss\n",
    "        losses_file=open(f'{external_path}\\\\features\\\\{layer}\\\\losses','wb')\n",
    "        pickle.dump(losses,losses_file)\n",
    "        losses_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_decomposition_to_features(concept_1,concept_2,layer,expansion_factor=4):\n",
    "\n",
    "    for k in range(1,11):\n",
    "        if k==1:\n",
    "            concept_1_activations=torch.load(f'{external_path}\\\\concept_token_activations\\\\{concept_1}\\\\layer{layer}_{k}.pt').squeeze(1)\n",
    "        else:\n",
    "            concept_1_activations=torch.cat([concept_1_activations,torch.load(f'{external_path}\\\\concept_token_activations\\\\{concept_1}\\\\layer{layer}_{k}.pt').squeeze(1)])\n",
    "\n",
    "    for k in range(1,11):\n",
    "        if k==1:\n",
    "            concept_2_activations=torch.load(f'{external_path}\\\\concept_token_activations\\\\{concept_2}\\\\layer{layer}_{k}.pt').squeeze(1)\n",
    "        else:\n",
    "            concept_2_activations=torch.cat([concept_2_activations,torch.load(f'{external_path}\\\\concept_token_activations\\\\{concept_2}\\\\layer{layer}_{k}.pt').squeeze(1)])\n",
    "    \n",
    "\n",
    "    sparse_autoencoder=AutoEncoder(concept_1_activations.shape[1],expansion_factor*concept_1_activations.shape[1])\n",
    "    sparse_autoencoder.load_state_dict(torch.load(f'{external_path}\\\\features\\\\{layer}\\\\{concept_1}_{concept_2}\\\\model.pt'))\n",
    "    sparse_autoencoder.eval()\n",
    "\n",
    "    c_concept_1=sparse_autoencoder.encoder(concept_1_activations@sparse_autoencoder.decoder.weight+sparse_autoencoder.encoder_bias)\n",
    "    c_concept_2=sparse_autoencoder.encoder(concept_2_activations@sparse_autoencoder.decoder.weight+sparse_autoencoder.encoder_bias)\n",
    "\n",
    "    torch.save(c_concept_1,f'{external_path}\\\\features\\\\{layer}\\\\{concept_1}_{concept_2}\\\\{concept_1}_decompositions.pt')\n",
    "    torch.save(c_concept_2,f'{external_path}\\\\features\\\\{layer}\\\\{concept_1}_{concept_2}\\\\{concept_2}_decompositions.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "truck_ship: 100%|██████████| 10/10 [00:42<00:00,  4.22s/it]        \n"
     ]
    }
   ],
   "source": [
    "layer=1\n",
    "pbar=tqdm(concepts)\n",
    "for positive_concept in pbar:\n",
    "    for negative_concept in concepts:\n",
    "        if positive_concept==negative_concept:\n",
    "            continue\n",
    "        pbar.set_description(f'{positive_concept}_{negative_concept}')\n",
    "        activation_decomposition_to_features(positive_concept,negative_concept,layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_similar_to_concept_vector(positive_concept,negative_concept,layer,concept_vector_type='cav',expansion_factor=4):\n",
    "\n",
    "    for k in range(1,11):\n",
    "        if k==1:\n",
    "            positive_concept_activations=torch.load(f'{external_path}\\\\concept_token_activations\\\\{positive_concept}\\\\layer{layer}_{k}.pt').squeeze(1)\n",
    "        else:\n",
    "            positive_concept_activations=torch.cat([positive_concept_activations,torch.load(f'{external_path}\\\\concept_token_activations\\\\{positive_concept}\\\\layer{layer}_{k}.pt').squeeze(1)])\n",
    "\n",
    "    sparse_autoencoder=AutoEncoder(positive_concept_activations.shape[1],expansion_factor*positive_concept_activations.shape[1])\n",
    "    sparse_autoencoder.load_state_dict(torch.load(f'{external_path}\\\\features\\\\{layer}\\\\{positive_concept}_{negative_concept}\\\\model.pt'))\n",
    "    sparse_autoencoder.eval()\n",
    "\n",
    "    feature_dictionary=sparse_autoencoder.decoder.weight.data\n",
    "\n",
    "    if concept_vector_type=='cav':\n",
    "        concept_vector=torch.load(f'{external_path}\\\\concept_activation_vectors\\\\{layer}\\\\{positive_concept}_{negative_concept}.pt')\n",
    "    elif concept_vector_type=='cbv':\n",
    "        concept_vector=torch.load(f'{external_path}\\\\concept_boundary_vectors\\\\{layer}\\\\{positive_concept}_{negative_concept}.pt')\n",
    "    else:\n",
    "        raise ValueError('Enter valid concept vector, either cav or cbv')\n",
    "\n",
    "    activation_decompositions=torch.cat([torch.load(f'{external_path}\\\\features\\\\{layer}\\\\{positive_concept}_{negative_concept}\\\\{positive_concept}_decompositions.pt'),torch.load(f'{external_path}\\\\features\\\\{layer}\\\\{positive_concept}_{negative_concept}\\\\{negative_concept}_decompositions.pt')])\n",
    "\n",
    "    sparsities=torch.sum(activation_decompositions>0,axis=0)/activation_decompositions.shape[0]\n",
    "    \n",
    "    alive_features=torch.where(sparsities>0)\n",
    "    alive_features_dictionary=feature_dictionary[:,alive_features[0]]\n",
    "\n",
    "    alive_features_dictionary=alive_features_dictionary-torch.mean(alive_features_dictionary,axis=1,keepdim=True)\n",
    "    \n",
    "    dots_with_concept_vector=np.zeros(alive_features_dictionary.shape[1])\n",
    "\n",
    "    for k in range(alive_features_dictionary.shape[1]):\n",
    "        dots_with_concept_vector[k]=(torch.dot(concept_vector,alive_features_dictionary[:,k])/torch.norm(alive_features_dictionary[:,k])).item()\n",
    "\n",
    "    most_similar_features=alive_features[0][np.argsort(dots_with_concept_vector)[-5:]]\n",
    "\n",
    "    firing_images_relative=np.zeros((5,5),dtype=int)\n",
    "    for n in range(5):\n",
    "        firing_images_relative[n,:]=torch.argsort(activation_decompositions[:,most_similar_features[-(n+1)]],descending=True)[:5].detach().numpy()\n",
    "\n",
    "    concept_correctly_classified_indices_file=open(f'{external_path}\\\\concept_correctly_classified_indices','rb')\n",
    "    concept_correctly_classified_indices=pickle.load(concept_correctly_classified_indices_file)\n",
    "    concept_correctly_classified_indices_file.close()\n",
    "\n",
    "    correctly_classified_indices=np.concatenate([concept_correctly_classified_indices[positive_concept],concept_correctly_classified_indices[negative_concept]])\n",
    "\n",
    "    firing_images_absolute=np.zeros((5,5),dtype=int)\n",
    "    for n in range(5):\n",
    "        firing_images_absolute[n,:]=correctly_classified_indices[firing_images_relative[n,:]]\n",
    "    \n",
    "    fig,axs=plt.subplots(nrows=5,ncols=5)\n",
    "    if concept_vector_type=='cav':\n",
    "        fig.suptitle('Features Most Similar to CAV')\n",
    "    elif concept_vector_type=='cbv':\n",
    "        fig.suptitle('Features Most Similar to CBV')\n",
    "    for n in range(5):\n",
    "        for k,instance in enumerate(test_set):\n",
    "            if k in firing_images_absolute[n,:]:\n",
    "                idx=np.where(firing_images_absolute[n,:]==k)[0][0]\n",
    "                axs[n,idx].imshow(np.array(instance['img']))\n",
    "                if idx==0:\n",
    "                    axs[n,idx].set_ylabel(str(most_similar_features[-(n+1)].item()))\n",
    "                    axs[n,idx].xaxis.set_visible(False)\n",
    "                    axs[n,idx].tick_params(left=False, labelleft=False)\n",
    "                else:\n",
    "                    axs[n,idx].axis('off')\n",
    "    plt.savefig(f'{external_path}\\\\features\\\\{layer}\\\\{positive_concept}_{negative_concept}\\\\most_similar_{positive_concept}_{negative_concept}_{concept_vector_type}.png')\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    np.save(f'{external_path}\\\\features\\\\{layer}\\\\{positive_concept}_{negative_concept}\\\\most_similar_{positive_concept}_{negative_concept}_{concept_vector_type}.npy',np.flip(most_similar_features.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer 1: truck_ship CBV: 100%|██████████| 10/10 [40:26<00:00, 242.68s/it]        \n"
     ]
    }
   ],
   "source": [
    "layer=1\n",
    "pbar=tqdm(concepts)\n",
    "for positive_concept in pbar:\n",
    "    for negative_concept in concepts:\n",
    "        if positive_concept==negative_concept:\n",
    "            continue\n",
    "        pbar.set_description(f'Layer {layer}: {positive_concept}_{negative_concept} CAV')\n",
    "        features_similar_to_concept_vector(positive_concept,negative_concept,layer)\n",
    "        pbar.set_description(f'Layer {layer}: {positive_concept}_{negative_concept} CBV')\n",
    "        features_similar_to_concept_vector(positive_concept,negative_concept,layer,concept_vector_type='cbv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_features(positive_concept,negative_concept,layer,expansion_factor=4):\n",
    "\n",
    "    for k in range(1,11):\n",
    "        if k==1:\n",
    "            positive_concept_activations=torch.load(f'{external_path}\\\\concept_token_activations\\\\{positive_concept}\\\\layer{layer}_{k}.pt').squeeze(1)\n",
    "        else:\n",
    "            positive_concept_activations=torch.cat([positive_concept_activations,torch.load(f'{external_path}\\\\concept_token_activations\\\\{positive_concept}\\\\layer{layer}_{k}.pt').squeeze(1)])\n",
    "\n",
    "    sparse_autoencoder=AutoEncoder(positive_concept_activations.shape[1],expansion_factor*positive_concept_activations.shape[1])\n",
    "    sparse_autoencoder.load_state_dict(torch.load(f'{external_path}\\\\features\\\\{layer}\\\\{positive_concept}_{negative_concept}\\\\model.pt'))\n",
    "    sparse_autoencoder.eval()\n",
    "\n",
    "    feature_dictionary=sparse_autoencoder.decoder.weight.data\n",
    "\n",
    "    activation_decompositions=torch.cat([torch.load(f'{external_path}\\\\features\\\\{layer}\\\\{positive_concept}_{negative_concept}\\\\{positive_concept}_decompositions.pt'),torch.load(f'{external_path}\\\\features\\\\{layer}\\\\{positive_concept}_{negative_concept}\\\\{negative_concept}_decompositions.pt')])\n",
    "\n",
    "    sparsities=torch.sum(activation_decompositions>0,axis=0)/activation_decompositions.shape[0]\n",
    "\n",
    "    alive_features=torch.where(sparsities>0)\n",
    "    alive_features_dictionary=feature_dictionary[:,alive_features[0]]\n",
    "\n",
    "    random_features=alive_features[0][np.random.choice(len(alive_features[0]),size=5,replace=False)]\n",
    "\n",
    "    firing_images_relative=np.zeros((5,5),dtype=int)\n",
    "    for n in range(5):\n",
    "        firing_images_relative[n,:]=torch.argsort(activation_decompositions[:,random_features[n]],descending=True)[:5].detach().numpy()\n",
    "\n",
    "    concept_correctly_classified_indices_file=open(f'{external_path}\\\\concept_correctly_classified_indices','rb')\n",
    "    concept_correctly_classified_indices=pickle.load(concept_correctly_classified_indices_file)\n",
    "    concept_correctly_classified_indices_file.close()\n",
    "\n",
    "    correctly_classified_indices=np.concatenate([concept_correctly_classified_indices[positive_concept],concept_correctly_classified_indices[negative_concept]])\n",
    "\n",
    "    firing_images_absolute=np.zeros((5,5),dtype=int)\n",
    "    for n in range(5):\n",
    "        firing_images_absolute[n,:]=correctly_classified_indices[firing_images_relative[n,:]]\n",
    "\n",
    "    fig,axs=plt.subplots(nrows=5,ncols=5)\n",
    "    fig.suptitle('Random Features')\n",
    "\n",
    "    for n in range(5):\n",
    "        for k,instance in enumerate(test_set):\n",
    "            if k in firing_images_absolute[n,:]:\n",
    "                idx=np.where(firing_images_absolute[n,:]==k)[0][0]\n",
    "                axs[n,idx].imshow(np.array(instance['img']))\n",
    "                if idx==0:\n",
    "                    axs[n,idx].set_ylabel(str(random_features[-(n+1)].item()))\n",
    "                    axs[n,idx].xaxis.set_visible(False)\n",
    "                    axs[n,idx].tick_params(left=False, labelleft=False)\n",
    "                else:\n",
    "                    axs[n,idx].axis('off')\n",
    "\n",
    "    plt.savefig(f'{external_path}\\\\features\\\\{layer}\\\\{positive_concept}_{negative_concept}\\\\random_{positive_concept}_{negative_concept}.png')\n",
    "\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer 1: truck_ship CAV: 100%|██████████| 10/10 [22:12<00:00, 133.27s/it]        \n"
     ]
    }
   ],
   "source": [
    "layer=1\n",
    "pbar=tqdm(concepts)\n",
    "for positive_concept in pbar:\n",
    "    for negative_concept in concepts:\n",
    "        if positive_concept==negative_concept:\n",
    "            continue\n",
    "        pbar.set_description(f'Layer {layer}: {positive_concept}_{negative_concept} CAV')\n",
    "        random_features(positive_concept,negative_concept,layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
