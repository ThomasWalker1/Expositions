{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "external_path='c:\\\\Users\\\\thoma\\\\Documents\\\\working_docs\\\\LIoT_aidos_external\\\\ViT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_dimension: int):\n",
    "        super().__init__()\n",
    "        self.in_dimension=in_dimension\n",
    "        self.linear=torch.nn.Linear(in_dimension,1)\n",
    "        self.sigmoid=torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(positive_concept,negative_concept,layer):\n",
    "    for k in range(1,11):\n",
    "        if k==1:\n",
    "            positive_concept_activations=torch.load(f'{external_path}\\\\concept_token_activations\\\\{positive_concept}\\\\layer{layer}_{k}.pt').squeeze(1)\n",
    "        else:\n",
    "            activations=torch.load(f'{external_path}\\\\concept_token_activations\\\\{positive_concept}\\\\layer{layer}_{k}.pt').squeeze(1)\n",
    "            positive_concept_activations=torch.cat([positive_concept_activations,activations])\n",
    "    \n",
    "    for k in range(1,11):\n",
    "        if k==1:\n",
    "            negative_concept_activations=torch.load(f'{external_path}\\\\concept_token_activations\\\\{negative_concept}\\\\layer{layer}_{k}.pt').squeeze(1)\n",
    "        else:\n",
    "            activations=torch.load(f'{external_path}\\\\concept_token_activations\\\\{negative_concept}\\\\layer{layer}_{k}.pt').squeeze(1)\n",
    "            negative_concept_activations=torch.cat([negative_concept_activations,activations])\n",
    "\n",
    "    dataset=torch.cat([positive_concept_activations,negative_concept_activations])\n",
    "    labels=torch.cat([torch.ones(positive_concept_activations.shape[0]),torch.zeros(negative_concept_activations.shape[0])])\n",
    "\n",
    "    return dataset,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cav(positive_concept,negative_concept,layer,lr=1e-3,batch_size=32,epochs=50):\n",
    "    dataset,labels=get_dataset(positive_concept,negative_concept,layer)\n",
    "\n",
    "    model=LinearClassifier(dataset.shape[1])\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion=torch.nn.BCELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss=0\n",
    "        epoch_cycles=dataset.shape[0]//batch_size\n",
    "        if dataset.shape[0]%batch_size==0:\n",
    "            epoch_cycles+=1\n",
    "        for k in range(epoch_cycles):\n",
    "            optimizer.zero_grad()\n",
    "            if k==epoch_cycles-1:\n",
    "                epoch_data=dataset[k*batch_size:]\n",
    "                epoch_labels=labels[k*batch_size:]\n",
    "            else:\n",
    "                epoch_data=dataset[k*batch_size:(k+1)*batch_size]\n",
    "                epoch_labels=labels[k*batch_size:(k+1)*batch_size]\n",
    "            outputs=model(epoch_data).T.squeeze(0)\n",
    "            loss=criterion(outputs,epoch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss+=loss.item()*len(epoch_labels)\n",
    "        epoch_loss/=dataset.shape[0]\n",
    "    cav=model.linear.weight[0].detach()\n",
    "    return cav/torch.norm(cav),epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer 11: truck_ship: 100%|██████████| 1/1 [19:25<00:00, 1165.66s/it]\n"
     ]
    }
   ],
   "source": [
    "pbar=tqdm(range(11,12))\n",
    "for layer in pbar:\n",
    "    if not(os.path.exists(f'{external_path}\\\\concept_activation_vectors\\\\{layer}')):\n",
    "        os.mkdir(f'{external_path}\\\\concept_activation_vectors\\\\{layer}')\n",
    "    losses={}\n",
    "    for positive_concept in concepts:\n",
    "        for negative_concept in concepts:\n",
    "            if positive_concept==negative_concept:\n",
    "                continue\n",
    "            pbar.set_description(f'Layer {layer}: {positive_concept}_{negative_concept}')\n",
    "            cav,loss=get_cav(positive_concept,negative_concept,layer)\n",
    "            torch.save(cav,f'{external_path}\\\\concept_activation_vectors\\\\{layer}\\\\{positive_concept}_{negative_concept}.pt')\n",
    "            losses[f'{positive_concept}_{negative_concept}']=loss\n",
    "    losses_file=open(f'{external_path}\\\\concept_activation_vectors\\\\{layer}\\\\losses','wb')\n",
    "    pickle.dump(losses,losses_file)\n",
    "    losses_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
